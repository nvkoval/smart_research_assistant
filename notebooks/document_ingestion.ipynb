{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f656b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Suppress HuggingFace warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration management for the Smart Research Assistant.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._setup_environment()\n",
    "\n",
    "    def _setup_environment(self):\n",
    "        \"\"\"Set up environment variables for LangChain and OpenAI.\"\"\"\n",
    "\n",
    "        load_dotenv()\n",
    "        # Verify required keys\n",
    "        missing_keys = []\n",
    "        for key in [\"OPENAI_API_KEY\", \"LANGSMITH_API_KEY\"]:\n",
    "            if not os.getenv(key):\n",
    "                missing_keys.append(key)\n",
    "\n",
    "        if missing_keys:\n",
    "            raise EnvironmentError(f\"Missing required environment variables: {', '.join(missing_keys)}\")\n",
    "\n",
    "        print(\"Environment successfully configured from .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f40aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    \"\"\"Handles document loading and text splitting.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        chunk_size: int = 500,\n",
    "        chunk_overlap: int = 50\n",
    "    ):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "\n",
    "    def load_and_split_documents(self, doc_paths: List[str]) -> List[Document]:\n",
    "        \"\"\"Loads PDF documents and split them into text chunks for processing.\"\"\"\n",
    "        print(f\"Loading and splitting {len(doc_paths)} documents...\")\n",
    "        all_chunks = []\n",
    "\n",
    "        for path in doc_paths:\n",
    "            if not Path(path).exists():\n",
    "                print(f\"Warning: Document not found at {path}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing: {path}\")\n",
    "            loader = PyMuPDFLoader(path)\n",
    "            documents = loader.load()\n",
    "            chunks = self.text_splitter.split_documents(documents)\n",
    "            all_chunks.extend(chunks)\n",
    "            print(f\"Generated {len(chunks)} chunks\")\n",
    "\n",
    "        print(f\"Total chunks created: {len(all_chunks)}\")\n",
    "        return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5fc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStoreManager:\n",
    "    \"\"\"Manages ChromaDB vector store operations.\"\"\"\n",
    "\n",
    "    def __init__(self, persist_dir: str = \"../data/chroma_db\",\n",
    "                 embedding_model: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.persist_dir = persist_dir\n",
    "        self.embedding_model = self._initialize_embeddings(embedding_model)\n",
    "        self.db: Optional[Chroma] = None\n",
    "\n",
    "    def _initialize_embeddings(self, model_name: str) -> HuggingFaceEmbeddings:\n",
    "        \"\"\"Initialize HuggingFace embeddings with Windows compatibility.\"\"\"\n",
    "        print(f\"Loading embedding model: {model_name}\")\n",
    "\n",
    "        model_kwargs = {\n",
    "            'device': 'cpu',\n",
    "            'trust_remote_code': True\n",
    "        }\n",
    "\n",
    "        encode_kwargs = {\n",
    "            'normalize_embeddings': True,\n",
    "            'batch_size': 32\n",
    "        }\n",
    "\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs\n",
    "        )\n",
    "        print(\"✓ Embedding model loaded successfully\")\n",
    "        return embeddings\n",
    "\n",
    "    def build_index(self, documents: list[Document]):\n",
    "        \"\"\"Create and persist vector index from document chunks.\"\"\"\n",
    "        print(\"Building ChromaDB index...\")\n",
    "\n",
    "        # Create the persist directory if it doesn't exist\n",
    "        Path(self.persist_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.db = Chroma.from_documents(\n",
    "            documents,\n",
    "            self.embedding_model,\n",
    "            persist_directory=self.persist_dir\n",
    "        )\n",
    "        print(f\"✓ Index built and saved to {self.persist_dir}\")\n",
    "\n",
    "    def load_index(self) -> None:\n",
    "        \"\"\"Load existing vector index from disk.\"\"\"\n",
    "        print(\"Loading existing ChromaDB index...\")\n",
    "\n",
    "        try:\n",
    "            self.db = Chroma(\n",
    "                persist_directory=self.persist_dir,\n",
    "                embedding_function=self.embedding_model\n",
    "            )\n",
    "\n",
    "            print(f\"✓ ChromaDB index loaded successfully from '{self.persist_dir}'\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load ChromaDB index: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_retriever(self, search_kwargs: Dict[str, Any] = None):\n",
    "        \"\"\"Get retriever for similarity search.\"\"\"\n",
    "        if not self.db:\n",
    "            raise ValueError(\"ChromaDB is not initialized. Call build_index() or load_index() first\")\n",
    "        if search_kwargs is None:\n",
    "            search_kwargs={\"k\": 3}\n",
    "\n",
    "        return self.db.as_retriever(search_kwargs=search_kwargs)\n",
    "\n",
    "    def index_exists(self) -> bool:\n",
    "        \"\"\"Check if vector index exists on disk.\"\"\"\n",
    "        persist_path = Path(self.persist_dir)\n",
    "\n",
    "        return persist_path.exists() and any(persist_path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9f20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAChainBuilder:\n",
    "    \"\"\"Builds and manages the conversational QA chain.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        temperature: float = 0,\n",
    "        model_name: str = \"gpt-4o-mini\"\n",
    "    ):\n",
    "        self.temperature = temperature\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def build_chain(self, retriever) -> ConversationalRetrievalChain:\n",
    "        \"\"\"Build conversational retrieval chain\"\"\"\n",
    "        llm = ChatOpenAI(\n",
    "            temperature=self.temperature,\n",
    "            model_name=self.model_name)\n",
    "\n",
    "        return ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            verbose=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf86689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormatter:\n",
    "    \"\"\"Formats responses with source citations.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def format_answer_with_sources(\n",
    "        result: Dict[str, Any],\n",
    "        max_source_length: int = 300) -> str:\n",
    "        \"\"\"Format answer with source document citations\"\"\"\n",
    "        answer = result.get('answer', 'No answer provided')\n",
    "        sources = result.get('source_documents', [])\n",
    "\n",
    "        if not sources:\n",
    "            return answer\n",
    "\n",
    "        formatted_response = answer + \"\\n\\n\" + \"=\"*50 + \"\\nSOURCES:\\n\" + \"=\"*50\n",
    "\n",
    "        for i, doc in enumerate(sources, 1):\n",
    "            source_path = doc.metadata.get('source', 'Unknown source')\n",
    "            source_page = doc.metadata.get('page', 'Unknown page')\n",
    "\n",
    "            formatted_response += f\"\\n\\nSource {i}: {Path(source_path).name} (Page: {source_page})\"\n",
    "            formatted_response += f\"\\n{doc.page_content[:max_source_length]}...\"\n",
    "\n",
    "        return formatted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e414501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartResearchAssistant:\n",
    "    \"\"\"Main class that orchestrates the RAG pipeline.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config = None):\n",
    "        self.config = config or Config()\n",
    "        self.document_processor = DocumentProcessor()\n",
    "        self.vector_store = VectorStoreManager()\n",
    "        self.qa_builder = QAChainBuilder()\n",
    "        self.formatter = ResponseFormatter()\n",
    "        self.qa_chain = None\n",
    "        self.chat_history = []\n",
    "\n",
    "    def setup(self, document_paths: List[str]):\n",
    "        \"\"\"Set up research assistant with documents.\"\"\"\n",
    "        # Process documents\n",
    "        chunks = self.document_processor.load_and_split_documents(document_paths)\n",
    "\n",
    "        if not chunks:\n",
    "            raise ValueError(\"No documents were successfully processed\")\n",
    "\n",
    "        # Setup vector store\n",
    "        if self.vector_store.index_exists():\n",
    "            self.vector_store.load_index()\n",
    "        else:\n",
    "            self.vector_store.build_index(chunks)\n",
    "\n",
    "        # Build QA chain\n",
    "        retriever = self.vector_store.get_retriever()\n",
    "        self.qa_chain = self.qa_builder.build_chain(retriever)\n",
    "        print(\"Smart Research Assistant is ready!\")\n",
    "\n",
    "    def ask_question(self, question: str) -> str:\n",
    "        \"\"\"Ask a question and get an answer with sources.\"\"\"\n",
    "        if not self.qa_chain:\n",
    "            raise ValueError(\"Assistant not set up. Call setup() first.\")\n",
    "\n",
    "        print(f\"\\nProcessing question: {question}\")\n",
    "\n",
    "        result = self.qa_chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"chat_history\": self.chat_history\n",
    "        })\n",
    "\n",
    "        # Update chat history\n",
    "        self.chat_history.append((question, result['answer']))\n",
    "        return self.formatter.format_answer_with_sources(result)\n",
    "\n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear chat history.\"\"\"\n",
    "        self.chat_history = []\n",
    "        print(\"Chat history cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b273ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "✓ Embedding model loaded successfully\n",
      "Loading and splitting 2 documents...\n",
      "Processing: ../data/docs/article1.pdf\n",
      "Generated 59 chunks\n",
      "Processing: ../data/docs/article2.pdf\n",
      "Generated 82 chunks\n",
      "Total chunks created: 141\n",
      "Building ChromaDB index...\n",
      "✓ Index built and saved to ../data/chroma_db\n",
      "Smart Research Assistant is ready!\n",
      "\n",
      "Processing question: How to handle Data Privacy?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "details are hidden before being sent to outside AI systems. Only approved people can see or change the data,\n",
      "and every action is tracked. The whole system can run inside a private company network if needed, meeting\n",
      "all required data protection laws.\n",
      "Written by: Sudip Dasgupta and Himanshu Shankar\n",
      "Page 9\n",
      "\n",
      "• If the AI Agent makes something up or is unsure, the answer is checked against rules and past correct\n",
      "answers, or the opinion of several agents.\n",
      "• If the AI Agent can’t handle a very important section, or its confidence is low, a human must check it.\n",
      "• All mistakes or special cases are recorded for future improvements.\n",
      "Section 7: Data Privacy and Compliance\n",
      "Because these documents can be sensitive, all information is encrypted and kept safe at every stage. Private\n",
      "\n",
      "• LangChain, CrewAI, Guidance, TruLens\n",
      "All tests and reviews with this prototype followed strict company privacy and security rules, and sensitive\n",
      "information was always kept safe.\n",
      "Written by: Sudip Dasgupta and Himanshu Shankar\n",
      "Page 11\n",
      "Human: How to handle Data Privacy?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Q: How to handle Data Privacy?\n",
      "A: To handle data privacy, it is important to follow these key practices:\n",
      "\n",
      "1. **Data Encryption**: Ensure that all sensitive information is encrypted at every stage to protect it from unauthorized access.\n",
      "\n",
      "2. **Access Control**: Limit access to data to only approved individuals who need it for their work. Implement strict authentication and authorization measures.\n",
      "\n",
      "3. **Tracking and Monitoring**: Keep a record of all actions taken on the data, including who accessed it and what changes were made. This helps in accountability and auditing.\n",
      "\n",
      "4. **Compliance with Laws**: Adhere to all relevant data protection laws and regulations to ensure that data handling practices are legal and ethical.\n",
      "\n",
      "5. **Regular Audits**: Conduct regular audits and reviews of data handling practices to identify and rectify any potential vulnerabilities.\n",
      "\n",
      "6. **Training and Awareness**: Provide training to employees about data privacy policies and best practices to ensure they understand the importance of protecting sensitive information.\n",
      "\n",
      "7. **Incident Response Plan**: Have a plan in place for responding to data breaches or privacy incidents, including notifying affected individuals and authorities as required.\n",
      "\n",
      "By implementing these practices, organizations can better protect sensitive data and maintain compliance with data privacy regulations.\n",
      "\n",
      "==================================================\n",
      "SOURCES:\n",
      "==================================================\n",
      "\n",
      "Source 1: article2.pdf (Page: 8)\n",
      "details are hidden before being sent to outside AI systems. Only approved people can see or change the data,\n",
      "and every action is tracked. The whole system can run inside a private company network if needed, meeting\n",
      "all required data protection laws.\n",
      "Written by: Sudip Dasgupta and Himanshu Shankar\n",
      "Pa...\n",
      "\n",
      "Source 2: article2.pdf (Page: 8)\n",
      "• If the AI Agent makes something up or is unsure, the answer is checked against rules and past correct\n",
      "answers, or the opinion of several agents.\n",
      "• If the AI Agent can’t handle a very important section, or its confidence is low, a human must check it.\n",
      "• All mistakes or special cases are recorded fo...\n",
      "\n",
      "Source 3: article2.pdf (Page: 10)\n",
      "• LangChain, CrewAI, Guidance, TruLens\n",
      "All tests and reviews with this prototype followed strict company privacy and security rules, and sensitive\n",
      "information was always kept safe.\n",
      "Written by: Sudip Dasgupta and Himanshu Shankar\n",
      "Page 11...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Processing question: What are the steps for question answering from documents?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: How to handle Data Privacy?\n",
      "Assistant: To handle data privacy, it is important to follow these key practices:\n",
      "\n",
      "1. **Data Encryption**: Ensure that all sensitive information is encrypted at every stage to protect it from unauthorized access.\n",
      "\n",
      "2. **Access Control**: Limit access to data to only approved individuals who need it for their work. Implement strict authentication and authorization measures.\n",
      "\n",
      "3. **Tracking and Monitoring**: Keep a record of all actions taken on the data, including who accessed it and what changes were made. This helps in accountability and auditing.\n",
      "\n",
      "4. **Compliance with Laws**: Adhere to all relevant data protection laws and regulations to ensure that data handling practices are legal and ethical.\n",
      "\n",
      "5. **Regular Audits**: Conduct regular audits and reviews of data handling practices to identify and rectify any potential vulnerabilities.\n",
      "\n",
      "6. **Training and Awareness**: Provide training to employees about data privacy policies and best practices to ensure they understand the importance of protecting sensitive information.\n",
      "\n",
      "7. **Incident Response Plan**: Have a plan in place for responding to data breaches or privacy incidents, including notifying affected individuals and authorities as required.\n",
      "\n",
      "By implementing these practices, organizations can better protect sensitive data and maintain compliance with data privacy regulations.\n",
      "Follow Up Input: What are the steps for question answering from documents?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "LLM to answer questions about the content of \n",
      "those documents to help users gain a deeper \n",
      "understanding and get access to the information \n",
      "that they need. Once LLMs can be utilized to \n",
      "process data that they were not originally trained \n",
      "for, there are many use cases that can be achieved. \n",
      "There are various steps involved in answering \n",
      "questions from own documents, as depicted in Fig \n",
      "4.  \n",
      " \n",
      " \n",
      "Fig. 4 Steps to answer questions from own documents.\n",
      "\n",
      "prompt. \n",
      "The other methods that can be used in processing \n",
      "documents when the retrieved documents do not fit \n",
      "in a single prompt are “map reduce,” “refine,” and \n",
      "“map rerank.” \n",
      "Map reduce takes all the chunks, passes them \n",
      "along with the question to a language model, gets \n",
      "back a response, and then uses another language \n",
      "model call to summarize all of the individual \n",
      "responses into a final answer. Map reduce can\n",
      "\n",
      "can be beneficial for auditing purposes or to \n",
      "enhance system performance through reflective \n",
      "analysis of past interactions. \n",
      "A.A.5 Question Answering from Documents \n",
      "One of the most common and complex \n",
      "applications that are being built using an LLM is a \n",
      "system that can answer questions on top of or \n",
      "about a document. Given a piece of text, extracted \n",
      "from a PDF file, a webpage, a csv file or another \n",
      "type of document, apps can be developed to use an\n",
      "Human: What are the steps for question answering from documents?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Q: What are the steps for question answering from documents?\n",
      "A: The steps for question answering from documents involve several methods, as depicted in the context provided. While the specific steps are not detailed in the text, it mentions that there are various methods to process documents, including \"map reduce,\" \"refine,\" and \"map rerank.\" \n",
      "\n",
      "1. **Map Reduce**: This method takes all the chunks of text, passes them along with the question to a language model, retrieves individual responses, and then summarizes those responses into a final answer.\n",
      "\n",
      "The context does not provide further specific steps, so I cannot elaborate beyond this.\n",
      "\n",
      "==================================================\n",
      "SOURCES:\n",
      "==================================================\n",
      "\n",
      "Source 1: article1.pdf (Page: 4)\n",
      "LLM to answer questions about the content of \n",
      "those documents to help users gain a deeper \n",
      "understanding and get access to the information \n",
      "that they need. Once LLMs can be utilized to \n",
      "process data that they were not originally trained \n",
      "for, there are many use cases that can be achieved. \n",
      "There are...\n",
      "\n",
      "Source 2: article1.pdf (Page: 4)\n",
      "prompt. \n",
      "The other methods that can be used in processing \n",
      "documents when the retrieved documents do not fit \n",
      "in a single prompt are “map reduce,” “refine,” and \n",
      "“map rerank.” \n",
      "Map reduce takes all the chunks, passes them \n",
      "along with the question to a language model, gets \n",
      "back a response, and then ...\n",
      "\n",
      "Source 3: article1.pdf (Page: 4)\n",
      "can be beneficial for auditing purposes or to \n",
      "enhance system performance through reflective \n",
      "analysis of past interactions. \n",
      "A.A.5 Question Answering from Documents \n",
      "One of the most common and complex \n",
      "applications that are being built using an LLM is a \n",
      "system that can answer questions on top of o...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Initialize the assistant\n",
    "config = Config()\n",
    "assistant = SmartResearchAssistant(config)\n",
    "\n",
    "# Document paths\n",
    "document_paths = [\n",
    "    \"../data/docs/article1.pdf\",\n",
    "    \"../data/docs/article2.pdf\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Setup the assistant\n",
    "    assistant.setup(document_paths)\n",
    "\n",
    "    questions = [\n",
    "        \"How to handle Data Privacy?\",\n",
    "        \"What are the steps for question answering from documents?\"\n",
    "    ]\n",
    "\n",
    "    # Process questions\n",
    "    for question in questions:\n",
    "        try:\n",
    "            answer = assistant.ask_question(question)\n",
    "            print(f\"\\nQ: {question}\")\n",
    "            print(f\"A: {answer}\")\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question '{question}': {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Setup error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67b415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "✓ Embedding model loaded successfully\n",
      "Loading and splitting 2 documents...\n",
      "Processing: ../data/docs/article1.pdf\n",
      "Generated 59 chunks\n",
      "Processing: ../data/docs/article2.pdf\n",
      "Generated 82 chunks\n",
      "Total chunks created: 141\n",
      "Loading existing ChromaDB index...\n",
      "✓ ChromaDB index loaded successfully from '../data/chroma_db'\n",
      "Smart Research Assistant is ready!\n",
      "\n",
      "Processing question: What are the main benefits of using Langchain systems?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "1052 \n",
      " \n",
      "with our own documents, as discussed in the \n",
      "following Question Answering from Documents \n",
      "section. \n",
      "A.A.3 Chains \n",
      "The most important key building block of \n",
      "LangChain is the chain. The chain usually \n",
      "combines an LLM together with a prompt, and \n",
      "with this building block, you can also put a bunch \n",
      "of these building blocks together to carry out a \n",
      "sequence of operations on your text or on your \n",
      "other data. \n",
      "A simple chain takes one input prompt and\n",
      "\n",
      "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/372669736\n",
      "Creating Large Language Model Applications Utilizing LangChain: A Primer on\n",
      "Developing LLM Apps Fast\n",
      "Article  in  International Conference on Applied Engineering and Natural Sciences · July 2023\n",
      "DOI: 10.59287/icaens.1127\n",
      "CITATIONS\n",
      "196\n",
      "READS\n",
      "32,328\n",
      "2 authors:\n",
      "Oguzhan Topsakal\n",
      "University of South Florida\n",
      "45 PUBLICATIONS   644 CITATIONS   \n",
      "SEE PROFILE\n",
      "T. Cetin Akinci\n",
      "\n",
      "an invaluable tool for the future of LLM \n",
      "applications. \n",
      "This paper provides insights into LangChain's \n",
      "structure \n",
      "and \n",
      "usage \n",
      "in \n",
      "specific \n",
      "use-cases, \n",
      "elucidating \n",
      "its \n",
      "capacity \n",
      "to \n",
      "foster \n",
      "rapid \n",
      "development. It is hoped that the potential and \n",
      "capabilities identified will spur more exploration \n",
      "and innovation in the field of LLMs and serve as a \n",
      "basis for the development of more sophisticated \n",
      "applications, thus expanding the boundaries of \n",
      "what is possible with artificial intelligence.\n",
      "Human: What are the main benefits of using Langchain systems?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Q: What are the main benefits of using Langchain systems?\n",
      "A: The main benefits of using LangChain systems include:\n",
      "\n",
      "1. **Rapid Development**: LangChain facilitates quick development of applications utilizing large language models (LLMs), allowing developers to create sophisticated applications more efficiently.\n",
      "\n",
      "2. **Modular Structure**: LangChain's architecture is built around chains, which combine LLMs with prompts and other building blocks. This modularity enables developers to easily assemble and customize workflows for various use cases.\n",
      "\n",
      "3. **Enhanced Capabilities**: By leveraging LangChain, developers can explore and innovate within the field of LLMs, expanding the boundaries of what is possible with artificial intelligence.\n",
      "\n",
      "4. **Support for Complex Operations**: LangChain allows for the combination of multiple operations on text or data, enabling more complex and nuanced interactions with LLMs.\n",
      "\n",
      "5. **Community and Resources**: The growing community and resources available for LangChain can provide support and inspiration for developers looking to implement LLM applications. \n",
      "\n",
      "These benefits make LangChain a valuable tool for developing LLM applications.\n",
      "\n",
      "==================================================\n",
      "SOURCES:\n",
      "==================================================\n",
      "\n",
      "Source 1: article1.pdf (Page: 3)\n",
      "1052 \n",
      " \n",
      "with our own documents, as discussed in the \n",
      "following Question Answering from Documents \n",
      "section. \n",
      "A.A.3 Chains \n",
      "The most important key building block of \n",
      "LangChain is the chain. The chain usually \n",
      "combines an LLM together with a prompt, and \n",
      "with this building block, you can also put a bun...\n",
      "\n",
      "Source 2: article1.pdf (Page: 0)\n",
      "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/372669736\n",
      "Creating Large Language Model Applications Utilizing LangChain: A Primer on\n",
      "Developing LLM Apps Fast\n",
      "Article  in  International Conference on Applied Engineering and Natural Scienc...\n",
      "\n",
      "Source 3: article1.pdf (Page: 6)\n",
      "an invaluable tool for the future of LLM \n",
      "applications. \n",
      "This paper provides insights into LangChain's \n",
      "structure \n",
      "and \n",
      "usage \n",
      "in \n",
      "specific \n",
      "use-cases, \n",
      "elucidating \n",
      "its \n",
      "capacity \n",
      "to \n",
      "foster \n",
      "rapid \n",
      "development. It is hoped that the potential and \n",
      "capabilities identified will spur more exploration ...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize the assistant\n",
    "config = Config()\n",
    "assistant = SmartResearchAssistant(config)\n",
    "\n",
    "# Document paths\n",
    "document_paths = [\n",
    "    \"../data/docs/article1.pdf\",\n",
    "    \"../data/docs/article2.pdf\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Setup the assistant\n",
    "    assistant.setup(document_paths)\n",
    "\n",
    "    questions = [\n",
    "        \"What are the main benefits of using Langchain systems?\"\n",
    "    ]\n",
    "\n",
    "    # Process questions\n",
    "    for question in questions:\n",
    "        try:\n",
    "            answer = assistant.ask_question(question)\n",
    "            print(f\"\\nQ: {question}\")\n",
    "            print(f\"A: {answer}\")\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question '{question}': {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Setup error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
